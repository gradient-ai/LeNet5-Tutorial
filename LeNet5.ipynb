{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddc0deed-1112-4fa9-a4b0-f3b9dcaf3cf1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "ddc0deed-1112-4fa9-a4b0-f3b9dcaf3cf1",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "## Writing Classic CNN LeNet5 from Scratch in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13949a7e-0e5b-415f-9918-d6222cfc01f1",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "13949a7e-0e5b-415f-9918-d6222cfc01f1",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "In this notebook, we would write one of the earliest Convolutional Neural Networks, LeNet5, from scratch in PyTorch. You can read more about it here: http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e66000-a4de-4b2c-bcde-13d1c53d6590",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a4e66000-a4de-4b2c-bcde-13d1c53d6590",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de3a5e-c5a0-4d1e-93b4-5da28116b48b",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "a2de3a5e-c5a0-4d1e-93b4-5da28116b48b",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "Let's start by importing the required libraries and defining some required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69990a8-b672-4745-be8e-049eb44b50d8",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "d69990a8-b672-4745-be8e-049eb44b50d8",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "\r\n",
    "batch_size = 64\r\n",
    "num_classes = 10\r\n",
    "learning_rate = 0.001\r\n",
    "num_epochs = 10\r\n",
    "\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5971b859-9f8c-405f-b50d-2256fd158dc0",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "5971b859-9f8c-405f-b50d-2256fd158dc0",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "### Downloading and Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef7e43a-f2b4-44c1-ac53-9c6dc11f0021",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "9ef7e43a-f2b4-44c1-ac53-9c6dc11f0021",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "We will download the datasets from `torchvision` and load them into PyTorch. We will also aply some transformations, such as resizing the images, converting them to tensors and normalizing them using the mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab776b18-1162-4600-9f41-8b39f0921784",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "ab776b18-1162-4600-9f41-8b39f0921784",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\r\n",
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                               | 0/9912422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███▊                       | 1417216/9912422 [00:00<00:00, 13372405.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████████████▋              | 4677632/9912422 [00:00<00:00, 16237172.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████████████████▋        | 6873088/9912422 [00:00<00:00, 17252987.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████████████████████▎ | 9289728/9912422 [00:00<00:00, 18846955.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\r\n",
      "\r\n",
      "\r",
      "0it [00:00, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\r\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\r\n",
      "\r\n",
      "\r\n",
      "\r",
      "0it [00:00, ?it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r",
      " 81%|█████████████████████▉     | 1343488/1648877 [00:00<00:00, 13389911.80it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "\r",
      "0it [00:00, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\r\n",
      "Processing...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:137.)\r\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "32768it [00:01, 31209.49it/s]\r\n",
      "\r",
      "1654784it [00:00, 1690035.65it/s]                                               \r\n",
      "\r",
      "8192it [00:00, 13435.85it/s]\r\n",
      "\r",
      "9920512it [00:02, 4430700.02it/s]                                               \r\n"
     ]
    }
   ],
   "source": [
    "!python test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba3973-1533-4e4e-a1d2-0b8653049683",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "89ba3973-1533-4e4e-a1d2-0b8653049683",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\r\n",
    "#Loading the dataset and preprocessing\r\n",
    "train_dataset = torchvision.datasets.MNIST(root = './data',\r\n",
    "                                              train = True,\r\n",
    "                                                  transform = transforms.Compose([\r\n",
    "                                                          transforms.Resize((32,32)),\r\n",
    "                                                          transforms.ToTensor(),\r\n",
    "                                                          transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\r\n",
    "                                                  download = False)\r\n",
    "\r\n",
    "\r\n",
    "test_dataset = torchvision.datasets.MNIST(root = './data',\r\n",
    "                                                  train = False,\r\n",
    "                                                  transform = transforms.Compose([\r\n",
    "                                                          transforms.Resize((32,32)),\r\n",
    "                                                  transforms.ToTensor(),\r\n",
    "                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),)\r\n",
    "\r\n",
    "\r\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\r\n",
    "                                           batch_size = batch_size,\r\n",
    "                                           shuffle = True)\r\n",
    "\r\n",
    "\r\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\r\n",
    "                                           batch_size = batch_size,\r\n",
    "               \r\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303f069b-9e7d-4d98-94c0-01b0296ce9f2",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "303f069b-9e7d-4d98-94c0-01b0296ce9f2",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "### LeNet5 From Scratch\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c996831-653a-45b1-8e24-3ce0aeb0af5c",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 5,
     "id": "4c996831-653a-45b1-8e24-3ce0aeb0af5c",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class ConvNeuralNet(nn.Module):\r\n",
    "    def __init__(self, num_classes):\r\n",
    "        super(ConvNeuralNet, self).__init__()\r\n",
    "        self.layer1 = nn.Sequential(\r\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\r\n",
    "            nn.BatchNorm2d(6),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\r\n",
    "        self.layer2 = nn.Sequential(\r\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\r\n",
    "            nn.BatchNorm2d(16),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\r\n",
    "        self.fc = nn.Linear(400, 120)\r\n",
    "        self.relu = nn.ReLU()\r\n",
    "        self.fc1 = nn.Linear(120, 84)\r\n",
    "        self.relu1 = nn.ReLU()\r\n",
    "        self.fc2 = nn.Linear(84, num_classes)\r\n",
    "        \r\n",
    "    def forward(self, x):\r\n",
    "        out = self.layer1(x)\r\n",
    "        out = self.layer2(out)\r\n",
    "        out = out.reshape(out.size(0), -1)\r\n",
    "        out = self.fc(out)\r\n",
    "        out = self.relu(out)\r\n",
    "        out = self.fc1(out)\r\n",
    "        out = self.relu1(out)\r\n",
    "        out = self.fc2(out)\r\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d28039-81ab-4fab-b8c2-32dcae2b5db4",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "56d28039-81ab-4fab-b8c2-32dcae2b5db4",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "### Setting Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d47060-cfd3-4bb0-affb-18d198b579d3",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 6,
     "id": "13d47060-cfd3-4bb0-affb-18d198b579d3",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "\r\n",
    "model = ConvNeuralNet( num_classes).to(device)\r\n",
    "\r\n",
    "#Defining cost and optimizer\r\n",
    "cost = nn.CrossEntropyLoss()\r\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3330d1-d3a0-407e-9bb9-dbc723fa5814",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "eb3330d1-d3a0-407e-9bb9-dbc723fa5814",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e778c82d-f08e-479b-86b7-c5484a859cc7",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "execution_count": 7,
     "id": "e778c82d-f08e-479b-86b7-c5484a859cc7",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [400/938], Loss: 0.0604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [800/938], Loss: 0.0857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [400/938], Loss: 0.0082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [800/938], Loss: 0.0119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [400/938], Loss: 0.0110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [800/938], Loss: 0.0154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [400/938], Loss: 0.0149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [800/938], Loss: 0.0438\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    for i, (images, labels) in enumerate(train_loader):  \r\n",
    "        images = images.to(device)\r\n",
    "        labels = labels.to(device)\r\n",
    "            #Forward pass\r\n",
    "        outputs = model(images)\r\n",
    "        loss = cost(outputs, labels)\r\n",
    "        \t\r\n",
    "        \t# Backward and optimize\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "        \t\t\r\n",
    "        if (i+1) % 400 == 0:\r\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \r\n",
    "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c599e80b-312f-4213-b078-5b5da4c028a4",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c599e80b-312f-4213-b078-5b5da4c028a4",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c"
    }
   },
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcae2d8-da84-4042-a391-46461adb5071",
   "metadata": {
    "collapsed": false,
    "gradient": {
     "editing": false,
     "id": "1dcae2d8-da84-4042-a391-46461adb5071",
     "kernelId": "13091908-caf9-4b4a-9f5e-e48fa5c71c3c",
     "source_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.81 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\r\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\r\n",
    "  \r\n",
    "with torch.no_grad():\r\n",
    "    correct = 0\r\n",
    "    total = 0\r\n",
    "    for images, labels in test_loader:\r\n",
    "        images = images.to(device)\r\n",
    "        labels = labels.to(device)\r\n",
    "        outputs = model(images)\r\n",
    "        _, predicted = torch.max(outputs.data, 1)\r\n",
    "        total += labels.size(0)\r\n",
    "        correct += (predicted == labels).sum().item()\r\n",
    "\r\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\r\n",
    "\t "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
